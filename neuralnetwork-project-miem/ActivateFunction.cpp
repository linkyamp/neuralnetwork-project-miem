#include "ActivateFunction.h"
void ActivateFunction::set() 
{
	std::cout << "This Network is based on ReLU activate functio\n";
}
void ActivateFunction::use(double* value, int n) {
//////////////////////////////////////////////////////////////////////////////
/// Функция активации, решающая, будет ли передано значение нейрона на следующий слой,
/// использует функцию ReLU
/// \param value - массив значений нейронов выходного слоя
/////////////////////////////////////////////////////////////////////////////
	for (int i = 0; i < n; i++) {
		if (value[i] < 0)
			value[i] *= 0.01;
		else if (value[i] > 1)
			value[i] = 1. + 0.01 * (value[i] - 1.);
	}
}
void ActivateFunction::useDer(double* value, int n) {
//////////////////////////////////////////////////////////////////////////////
/// Функция активации, решающая, будет ли передано значение нейрона на следующий слой
/// ,использует клон активационной функции ReLU
/// \param value - массив значений нейронов выходного слоя
/////////////////////////////////////////////////////////////////////////////
	for (int i = 0; i < n; i++) {
		if (value[i] < 0 || value[i] > 1)
			value[i] = 0.01;
		else
			value[i] = 1;
	}
}

double ActivateFunction::useDer(double value)
//////////////////////////////////////////////////////////////////////////////
/// Аналагична use, но не имеет цикла, так как применяется
/// для единственного нейрона, а не для целого слоя.
/// Возвращает результат в виде числа типа double
/// \param value - массив значений нейронов выходного слоя
/////////////////////////////////////////////////////////////////////////////
{
	if (value < 0 || value > 1)
		value = 0.01;
	return value;
}